"""
Script Ä‘á»ƒ Ä‘á»c Parquet files Ä‘Ã£ Ä‘Æ°á»£c share
NgÆ°á»i nháº­n dÃ¹ng script nÃ y Ä‘á»ƒ Ä‘á»c dá»¯ liá»‡u
"""

from pyspark.sql import SparkSession

# ÄÆ°á»ng dáº«n Ä‘áº¿n folder Parquet (thay Ä‘á»•i theo vá»‹ trÃ­ táº£i vá»)
PARQUET_PATH = "D:/Download/stock_bronze_parquet"  # Sá»­a path nÃ y

print("="*60)
print("READ SHARED PARQUET DATA")
print("="*60)

# Initialize Spark
spark = SparkSession.builder \
    .appName("Read Shared Parquet") \
    .getOrCreate()

print(f"\nğŸ“– Reading Parquet from: {PARQUET_PATH}")

# Read Parquet
df = spark.read.parquet(PARQUET_PATH)

print("\nğŸ“Š Schema:")
df.printSchema()

print("\nğŸ“ˆ Total records:", df.count())

print("\nğŸ” Sample data:")
df.show(10, truncate=False)

print("\nğŸ“Š Records by sector:")
df.groupBy("sector").count().orderBy("count", ascending=False).show()

print("\nğŸ“Š Latest 10 records:")
df.orderBy("ingest_time", ascending=False).show(10, truncate=False)

print("\nâœ… Data loaded successfully!")
print("="*60)

# Keep Spark session open for interactive queries
print("\nSpark session is ready. You can run queries like:")
print("  df.filter(df.symbol == 'AAPL').show()")
print("  df.groupBy('sector').agg({'close': 'avg'}).show()")

# Uncomment to stop Spark when done
# spark.stop()
